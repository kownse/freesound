{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874554394ba54bde8ebfc5db1600d7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, random, math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm_notebook, tqdm_pandas\n",
    "tqdm_notebook().pandas(smoothing=0.7)\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import kaggle_util\n",
    "from util import *\n",
    "\n",
    "DEBUG = 1\n",
    "nfold = 5\n",
    "nround = 1500\n",
    "if DEBUG:\n",
    "    nfold = 2\n",
    "    nround = 5\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 138/402 [00:00<00:00, 1370.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 3.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 402/402 [00:00<00:00, 1557.74it/s]\n",
      " 34%|███▍      | 137/401 [00:00<00:00, 1361.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.78 MB\n",
      "Decreased by 74.4%\n",
      "Memory usage of dataframe is 3.06 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:00<00:00, 1583.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.78 MB\n",
      "Decreased by 74.4%\n"
     ]
    }
   ],
   "source": [
    "nrows = None if not DEBUG else 1000\n",
    "\n",
    "train = kaggle_util.reduce_mem_usage(pd.read_csv('../data/train_mel.csv', nrows=nrows))\n",
    "test = kaggle_util.reduce_mem_usage(pd.read_csv('../data/test_mel.csv', nrows=nrows))\n",
    "y = pd.get_dummies(train.label)\n",
    "\n",
    "LABELS = list(train.label.unique())\n",
    "n_categories = len(LABELS)\n",
    "train = train.drop(['fname', 'label', 'manually_verified'], axis=1)\n",
    "feature_names = list(test.drop(['fname', 'label'], axis=1).columns.values)\n",
    "test = test.drop(['fname', 'label'], axis=1).values\n",
    "\n",
    "\n",
    "labels = y.columns.values\n",
    "y_label = y.values\n",
    "y_label = [np.argmax(row) for row in y_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 399) (511, 399)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 3.56912\n",
      "Score = 0.3092\n",
      "(511, 399) (489, 399)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 3.5467\n",
      "Score = 0.3231\n"
     ]
    }
   ],
   "source": [
    "PREDICTION_FOLDER = '../result/predictions/lgb'\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "\n",
    "cvscores = []\n",
    "skf = StratifiedKFold(y_label, n_folds=nfold)\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    X_train = train.iloc[train_split].values\n",
    "    y_train = [np.argmax(row) for row in y.iloc[train_split].values] \n",
    "    X_valid = train.iloc[val_split].values\n",
    "    y_valid = [np.argmax(row) for row in y.iloc[val_split].values] \n",
    "    \n",
    "    print(X_train.shape, X_valid.shape)\n",
    "    \n",
    "    d_train = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid, feature_name=feature_names)\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'num_threads': os.cpu_count(),\n",
    "        'lambda_l2': 1.0,\n",
    "        'min_gain_to_split': 0,\n",
    "        'num_class': n_categories,\n",
    "    }\n",
    "    \n",
    "    clf = lgb.train(params, d_train, num_boost_round=nround, \n",
    "                    valid_sets=d_valid, verbose_eval=100, \n",
    "                    early_stopping_rounds=100)\n",
    "    p = clf.predict(X_valid, num_iteration=clf.best_iteration)\n",
    "\n",
    "    #predictions = [list(np.argsort(p[i])[::-1][:3]) for i in range(len(p))]\n",
    "    #actual = [[i] for i in y_valid]\n",
    "    #valid_score = mapk(actual, predictions, k=3)\n",
    "    valid_score = get_valid_score(y_valid, p)\n",
    "    print(\"Score = {:.4f}\".format(valid_score))\n",
    "    cvscores.append(valid_score)\n",
    "    \n",
    "    pre_test = clf.predict(test, num_iteration=clf.best_iteration)\n",
    "    savepath = \"/p{}.npy\"\n",
    "    savepath = savepath.format(i)\n",
    "    np.save(PREDICTION_FOLDER + savepath, pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.316 std 0.007\n",
      "ensemble...\n",
      "      sub0\n",
      "sub0   1.0\n",
      "save result\n"
     ]
    }
   ],
   "source": [
    "cvmean = np.mean(cvscores)\n",
    "cvstd = np.std(cvscores)\n",
    "print('mean {0:.3f} std {1:.3f}'.format(cvmean, cvstd))\n",
    "actual_prefix = '{:.2f}_{:.2f}'.format(cvmean, cvstd)\n",
    "ensemble(LABELS, nfold, [PREDICTION_FOLDER], actual_prefix, 'lgb', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectral_features(fname=None, root=None, n_mels=32, return_fnames=False):\n",
    "    feature_names = []\n",
    "    for i in ['mean', 'std', 'min', 'max', 'skew', 'kurt']:\n",
    "        for j in range(n_mels):\n",
    "            feature_names.append('mel_{}_{}'.format(j, i))\n",
    "    \n",
    "    if return_fnames:\n",
    "        return feature_names\n",
    "\n",
    "     \n",
    "    try:\n",
    "        data, fs = librosa.core.load(root + fname, sr=None)\n",
    "        n_fft = 2048\n",
    "        stft = librosa.stft(data, n_fft=n_fft, hop_length=512)\n",
    "        mel_basis = librosa.filters.mel(fs, n_fft, n_mels)\n",
    "        s = np.dot(mel_basis, np.abs(stft)**2.0)\n",
    "        M = librosa.power_to_db(s, ref=np.max)\n",
    "        \n",
    "        data_row = np.hstack((np.mean(M, axis=1), np.std(M, axis=1), np.min(M, axis=1),\n",
    "                              np.max(M, axis=1), skew(M, axis=1), kurtosis(M, axis=1)))\n",
    "        \n",
    "        return pd.Series(data_row)\n",
    "        \n",
    "    except:\n",
    "        print(\"Bad file at {}\".format(fname))\n",
    "        return pd.Series([0]*len(feature_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seg = pd.read_csv('../data/train_seg.csv', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fname'].progress_apply(mel_spectral_features, root=train_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectral_features(return_fnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
